{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4a9d96d-f11f-4870-ad4e-ac4713390940",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b0d48ad-64b4-4af4-a54d-ff9d4d206b98",
   "metadata": {},
   "source": [
    "Download datasets from bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "443c5694-29f9-4b6d-9e5a-f2ce547f63ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: data/casia-100/.DS_Store: No such file or directory\n",
      "rm: data/digiface_subjects_0-1999_72_imgs/.DS_Store: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm data/casia-100/.DS_Store\n",
    "!rm data/digiface_subjects_0-1999_72_imgs/.DS_Store"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8183f419",
   "metadata": {},
   "source": [
    "Load test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46dbadca-5135-42a7-ab01-2694e81f4827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),  \n",
    "])\n",
    "\n",
    "train_data_path = 'data/train/casia-100'\n",
    "test_data_path = 'data/test/casia-100'\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_data = datasets.ImageFolder(train_data_path, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "test_data = datasets.ImageFolder(test_data_path, transform=train_transform)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6b8ea9a-6cdb-48a1-bc59-425666287fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11790\n",
      "2896\n",
      "image torch.Size([3, 112, 112])\n",
      "label tensor(93)\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(train_loader)\n",
    "image, label = next(iterator)\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "\n",
    "print(\"image\", image[0].shape)\n",
    "print(\"label\", label[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b07a322d",
   "metadata": {},
   "source": [
    "Load digiface pretrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "926e5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_data_path = 'data/digiface_subjects_0-1999_72_imgs'\n",
    "\n",
    "pretrain_data = datasets.ImageFolder(pretrain_data_path, transform=train_transform)\n",
    "pretrain_loader = torch.utils.data.DataLoader(\n",
    "    pretrain_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cfb65d31",
   "metadata": {},
   "source": [
    "Load casia pretrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_data_path_casia = 'data/casia-144000'\n",
    "\n",
    "pretrain_data_casia = datasets.ImageFolder(pretrain_data_path_casia, transform=train_transform)\n",
    "pretrain_loader_casia = torch.utils.data.DataLoader(\n",
    "    pretrain_data_casia, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2893d970-01b1-4501-9e4c-484bf87e48d2",
   "metadata": {},
   "source": [
    "# Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e610a2b7-4e25-4a03-a0cb-4a69cfa0c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch import nn, optim\n",
    "import os\n",
    "model = resnet18()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b865bab-fffd-416c-86e7-331408ede964",
   "metadata": {},
   "source": [
    "# Train and validate the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8eabf189",
   "metadata": {},
   "source": [
    "functions for training and validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf92ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_accuracy(model: nn.Module, train=False):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    n = 0\n",
    "    loader = train_loader if train else test_loader \n",
    "    predictions, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in iter(loader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            model.eval()\n",
    "            output = model(imgs).data\n",
    "            pred = output.max(1)[1]\n",
    "            correct += pred.eq(labels.data).sum().item()\n",
    "            total += imgs.shape[0]\n",
    "            predictions.append(pred)\n",
    "            labels.append(labels)\n",
    "            n += 1\n",
    "    return correct / total, predictions, labels\n",
    "\n",
    "def plot_training_curve(iters, losses, batches, train_acc, val_acc):\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    #save plot to file\n",
    "    time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    plt.savefig(\"figures/loss_curve_{}.png\".format(time))\n",
    "\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.plot(batches, train_acc, label=\"Train\")\n",
    "    plt.plot(batches, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    plt.savefig(\"figures/learning_curve_{}.png\".format(time))\n",
    "\n",
    "def train(\n",
    "    learning_rate = 0.1,\n",
    "    num_epochs = 22,\n",
    "    weight_decay = 0.0,\n",
    "    momentum = 0.9,\n",
    "    output_to_file = True,\n",
    "    always_output = True, \n",
    "    scheduling = False,\n",
    "    lr_milestones = [8, 16, 20],\n",
    "    lr_gamma = 0.1,\n",
    "    eval = True,\n",
    "    data_loader = train_loader,\n",
    "    loss_output_mod = 10,\n",
    "    filename_prefix = 'model',\n",
    "    savestate = True,\n",
    "    ):\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer, milestones=lr_milestones, gamma=lr_gamma)\n",
    "\n",
    "    if output_to_file:\n",
    "        outputfile = open('output_'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'.txt', 'w')\n",
    "\n",
    "    def output(text):\n",
    "        if output_to_file:\n",
    "            outputfile.write(text + '\\n')\n",
    "        else:\n",
    "            print(text)\n",
    "\n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    n = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_tic = time.perf_counter()\n",
    "        for imgs, labels in iter(data_loader):\n",
    "            tic = time.perf_counter()\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            out = model(imgs)\n",
    "            loss = loss_fn(out, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            toc = time.perf_counter()\n",
    "\n",
    "            if (n % loss_output_mod == 0) or always_output:\n",
    "                output('epoch: {}, iter: {}, loss: {}, time: {}'.format(epoch, n, loss, toc - tic))\n",
    "            if eval:\n",
    "                iters.append(n)\n",
    "                losses.append(float(loss)/batch_size) # compute *average* loss\n",
    "            n += 1\n",
    "\n",
    "        if eval: \n",
    "            curr_train_acc = get_accuracy(model, train=True)[0]\n",
    "            curr_val_acc = get_accuracy(model, train=False)[0]\n",
    "            train_acc.append(curr_train_acc) # compute training accuracy \n",
    "            val_acc.append(curr_val_acc)  # compute validation accuracy\n",
    "        \n",
    "        if savestate:\n",
    "            torch.save(model.state_dict(), 'model-states/' + filename_prefix + '_epoch_' + str(epoch) + '.pt')\n",
    "        \n",
    "        if scheduling:\n",
    "            lr_scheduler.step() \n",
    "\n",
    "        epoch_toc = time.perf_counter()\n",
    "        output('epoch: {}, time: {}'.format(epoch, epoch_toc - epoch_tic))\n",
    "        if output_to_file:\n",
    "            outputfile.flush()\n",
    "\n",
    "    if eval: \n",
    "        output(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "        output(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
    "        plot_training_curve(iters, losses, train_acc, val_acc)\n",
    "    else: \n",
    "        torch.save(model.state_dict(), 'model-states/' + filename_prefix + '_final.pt')\n",
    "        output(\"Final Training Accuracy: {}\".format(get_accuracy(model, train=True)))\n",
    "        # output(\"Final Validation Accuracy: {}\".format(get_accuracy(model, train=False)))\n",
    "    \n",
    "    if output_to_file:\n",
    "        outputfile.close()\n",
    "    \n",
    "    if eval:\n",
    "        return get_accuracy(model, train=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f420856",
   "metadata": {},
   "source": [
    "Perform experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "696bc0ad",
   "metadata": {},
   "source": [
    "Pretrain on digiface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac855f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "num_classes_pretrain = 2000\n",
    "model.fc = nn.Linear(512, num_classes_pretrain)\n",
    "model.to(device)\n",
    "\n",
    "train(\n",
    "    eval=False,\n",
    "    data_loader=pretrain_loader,\n",
    "    learning_rate=1e-3,\n",
    "    num_epochs=20,\n",
    "    output_to_file=False,\n",
    "    always_output=False,\n",
    "    scheduling=False,\n",
    "    loss_output_mod=100,\n",
    "    savestate=False,\n",
    "    filename_prefix='digiface_pretrained',\n",
    "      )\n",
    "\n",
    "pretrained_model_digiface = copy.deepcopy(model)\n",
    "#load state dict from model-states/digiface_pretrained_final.pt\n",
    "pretrained_model_digiface.load_state_dict(torch.load('model-states/digiface_pretrained_final.pt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8b3cfb0",
   "metadata": {},
   "source": [
    "Train and eval on first 100 casia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pretrained_model_digiface\n",
    "model.fc = nn.Linear(512, 100)\n",
    "model.to(device)\n",
    "\n",
    "acc, predictions, labels = train(\n",
    "    num_epochs=20,\n",
    "    learning_rate=0.1,\n",
    "    eval=True,\n",
    "    data_loader=train_loader,\n",
    "    output_to_file=False,\n",
    "    always_output=True,\n",
    "    scheduling=True,\n",
    "    filename_prefix='digiface_casia',\n",
    "    savestate=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99b853c5",
   "metadata": {},
   "source": [
    "Pretrain on casia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0e82685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994\n"
     ]
    }
   ],
   "source": [
    "num_classes_pretrain = len(os.listdir('data/casia-144000/'))\n",
    "print(num_classes_pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "model = resnet18()\n",
    "model.fc = nn.Linear(512, num_classes_pretrain)\n",
    "model.to(device)\n",
    "\n",
    "train(\n",
    "    eval=False,\n",
    "    data_loader=pretrain_loader_casia,\n",
    "    learning_rate=1e-3,\n",
    "    num_epochs=20,\n",
    "    output_to_file=False,\n",
    "    always_output=False,\n",
    "    scheduling=False,\n",
    "    loss_output_mod=100,\n",
    "    savestate=False,\n",
    "    filename_prefix='casia_pretrained',\n",
    "      )\n",
    "\n",
    "pretrained_model_casia = copy.deepcopy(model)\n",
    "pretrained_model_casia.load_state_dict(torch.load('model-states/casia_pretrained_final.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b0de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pretrained_model_casia\n",
    "model.fc = nn.Linear(512, 100)\n",
    "model.to(device)\n",
    "\n",
    "acc, predictions, labels = train(\n",
    "    num_epochs=20,\n",
    "    learning_rate=0.1,\n",
    "    eval=True,\n",
    "    data_loader=train_loader,\n",
    "    output_to_file=False,\n",
    "    always_output=True,\n",
    "    scheduling=True,\n",
    "    filename_prefix='casia_casia',\n",
    "    savestate=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77593b58",
   "metadata": {},
   "source": [
    "Load a resnet model with imagenet weights and train/eval again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807365c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(weights = ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(512, 100)\n",
    "model.to(device)\n",
    "\n",
    "acc, predictions, labels = train(\n",
    "    num_epochs=20,\n",
    "    learning_rate=0.1,\n",
    "    eval=True,\n",
    "    data_loader=train_loader,\n",
    "    output_to_file=False,\n",
    "    always_output=True,\n",
    "    scheduling=True,\n",
    "    filename_prefix='imagenet_casia',\n",
    "    savestate=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0346f00c",
   "metadata": {},
   "source": [
    "Load a clean resnet18 without any weights and train/eval again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18()\n",
    "model.fc = nn.Linear(512, 100)\n",
    "model.to(device)\n",
    "acc, predictions, labels = train(\n",
    "    num_epochs=20,\n",
    "    learning_rate=0.1,\n",
    "    eval=True,\n",
    "    data_loader=train_loader,\n",
    "    output_to_file=False,\n",
    "    always_output=True,\n",
    "    scheduling=True,\n",
    "    filename_prefix='imagenet_casia',\n",
    "    savestate=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6aa12045",
   "metadata": {},
   "source": [
    "Reset experminent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
