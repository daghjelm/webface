{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4a9d96d-f11f-4870-ad4e-ac4713390940",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b0d48ad-64b4-4af4-a54d-ff9d4d206b98",
   "metadata": {},
   "source": [
    "Download datasets from bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "443c5694-29f9-4b6d-9e5a-f2ce547f63ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: data/casia-100/.DS_Store: No such file or directory\n",
      "rm: data/digiface_subjects_0-1999_72_imgs/.DS_Store: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm data/casia-100/.DS_Store\n",
    "!rm data/digiface_subjects_0-1999_72_imgs/.DS_Store"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8183f419",
   "metadata": {},
   "source": [
    "Load test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46dbadca-5135-42a7-ab01-2694e81f4827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),  \n",
    "])\n",
    "\n",
    "train_data_path = 'data/train/casia-100'\n",
    "test_data_path = 'data/test/casia-100'\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_data = datasets.ImageFolder(train_data_path, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "test_data = datasets.ImageFolder(test_data_path, transform=train_transform)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6b8ea9a-6cdb-48a1-bc59-425666287fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11790\n",
      "2896\n",
      "image torch.Size([3, 112, 112])\n",
      "label tensor(9)\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(train_loader)\n",
    "image, label = next(iterator)\n",
    "print(len(train_data))\n",
    "print(len(test_data))\n",
    "\n",
    "print(\"image\", image[0].shape)\n",
    "print(\"label\", label[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b07a322d",
   "metadata": {},
   "source": [
    "Load digiface pretrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "926e5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_data_path = 'data/digiface_subjects_0-1999_72_imgs'\n",
    "\n",
    "pretrain_data = datasets.ImageFolder(pretrain_data_path, transform=train_transform)\n",
    "pretrain_loader = torch.utils.data.DataLoader(\n",
    "    pretrain_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cfb65d31",
   "metadata": {},
   "source": [
    "Load casia pretrain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3683a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_data_path_casia = 'data/casia-144000'\n",
    "\n",
    "pretrain_data_casia = datasets.ImageFolder(pretrain_data_path_casia, transform=train_transform)\n",
    "pretrain_loader_casia = torch.utils.data.DataLoader(\n",
    "    pretrain_data_casia, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2893d970-01b1-4501-9e4c-484bf87e48d2",
   "metadata": {},
   "source": [
    "# Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e610a2b7-4e25-4a03-a0cb-4a69cfa0c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch import nn, optim\n",
    "import os\n",
    "model = resnet18()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3b865bab-fffd-416c-86e7-331408ede964",
   "metadata": {},
   "source": [
    "# Train and validate the model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8eabf189",
   "metadata": {},
   "source": [
    "functions for training and validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf92ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_accuracy(model: nn.Module, train=False):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    n = 0\n",
    "    loader = train_loader if train else test_loader \n",
    "    predictions, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in iter(loader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            model.eval()\n",
    "            output = model(imgs).data\n",
    "            pred = output.max(1)[1]\n",
    "            correct += pred.eq(labels.data).sum().item()\n",
    "            total += imgs.shape[0]\n",
    "            predictions.append(pred)\n",
    "            labels.append(labels)\n",
    "            n += 1\n",
    "    return correct / total, predictions, labels\n",
    "\n",
    "def plot_training_curve(iters, losses, batches, train_acc, val_acc):\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.plot(iters, losses, label=\"Train\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    #save plot to file\n",
    "    time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    plt.savefig(\"figures/loss_curve_{}.png\".format(time))\n",
    "\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.plot(batches, train_acc, label=\"Train\")\n",
    "    plt.plot(batches, val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Iterations\")\n",
    "    plt.ylabel(\"Training Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    plt.savefig(\"figures/learning_curve_{}.png\".format(time))\n",
    "\n",
    "def train(\n",
    "    learning_rate = 0.1,\n",
    "    num_epochs = 22,\n",
    "    weight_decay = 0.0,\n",
    "    momentum = 0.9,\n",
    "    output_to_file = True,\n",
    "    always_output = True, \n",
    "    scheduling = False,\n",
    "    lr_milestones = [8, 16, 20],\n",
    "    lr_gamma = 0.1,\n",
    "    eval = True,\n",
    "    data_loader = train_loader,\n",
    "    loss_output_mod = 10,\n",
    "    filename_prefix = 'model',\n",
    "    savestate = True,\n",
    "    ):\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=learning_rate,\n",
    "        momentum=momentum,\n",
    "        weight_decay=weight_decay\n",
    "        )\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "        optimizer, milestones=lr_milestones, gamma=lr_gamma)\n",
    "\n",
    "    if output_to_file:\n",
    "        outputfile = open('output_'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+'.txt', 'w')\n",
    "\n",
    "    def output(text):\n",
    "        if output_to_file:\n",
    "            outputfile.write(text + '\\n')\n",
    "        else:\n",
    "            print(text)\n",
    "\n",
    "    iters, losses, train_acc, val_acc = [], [], [], []\n",
    "\n",
    "    n = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_tic = time.perf_counter()\n",
    "        for imgs, labels in iter(data_loader):\n",
    "            tic = time.perf_counter()\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            out = model(imgs)\n",
    "            print(out.shape)\n",
    "            print(labels.shape)\n",
    "            \n",
    "            loss = loss_fn(out, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            toc = time.perf_counter()\n",
    "\n",
    "            if (n % loss_output_mod == 0) or always_output:\n",
    "                output('epoch: {}, iter: {}, loss: {}, time: {}'.format(epoch, n, loss, toc - tic))\n",
    "            if eval:\n",
    "                iters.append(n)\n",
    "                losses.append(float(loss)/batch_size) # compute *average* loss\n",
    "            n += 1\n",
    "\n",
    "        if eval: \n",
    "            curr_train_acc = get_accuracy(model, train=True)[0]\n",
    "            curr_val_acc = get_accuracy(model, train=False)[0]\n",
    "            train_acc.append(curr_train_acc) # compute training accuracy \n",
    "            val_acc.append(curr_val_acc)  # compute validation accuracy\n",
    "        \n",
    "        if savestate:\n",
    "            torch.save(model.state_dict(), 'model-states/' + filename_prefix + '_epoch_' + str(epoch) + '.pt')\n",
    "        \n",
    "        if scheduling:\n",
    "            lr_scheduler.step() \n",
    "\n",
    "        epoch_toc = time.perf_counter()\n",
    "        output('epoch: {}, time: {}'.format(epoch, epoch_toc - epoch_tic))\n",
    "        if output_to_file:\n",
    "            outputfile.flush()\n",
    "\n",
    "    if eval: \n",
    "        output(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "        output(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
    "        plot_training_curve(iters, losses, train_acc, val_acc)\n",
    "    else: \n",
    "        torch.save(model.state_dict(), 'model-states/' + filename_prefix + '_final.pt')\n",
    "        output(\"Final Training Accuracy: {}\".format(get_accuracy(model, train=True)))\n",
    "        # output(\"Final Validation Accuracy: {}\".format(get_accuracy(model, train=False)))\n",
    "    \n",
    "    if output_to_file:\n",
    "        outputfile.close()\n",
    "    \n",
    "    if eval:\n",
    "        return get_accuracy(model, train=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f420856",
   "metadata": {},
   "source": [
    "Perform experiment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "696bc0ad",
   "metadata": {},
   "source": [
    "Pretrain on digiface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ac855f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "epoch: 0, iter: 0, loss: 7.707782745361328, time: 0.779980915998749\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n",
      "torch.Size([256, 2000])\n",
      "torch.Size([256])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[39m.\u001b[39mfc \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(\u001b[39m512\u001b[39m, num_classes_pretrain)\n\u001b[1;32m      5\u001b[0m model\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 7\u001b[0m train(\n\u001b[1;32m      8\u001b[0m     \u001b[39meval\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m      9\u001b[0m     data_loader\u001b[39m=\u001b[39;49mpretrain_loader,\n\u001b[1;32m     10\u001b[0m     learning_rate\u001b[39m=\u001b[39;49m\u001b[39m1e-3\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     num_epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     output_to_file\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     13\u001b[0m     always_output\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     14\u001b[0m     scheduling\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     15\u001b[0m     loss_output_mod\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m     savestate\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     17\u001b[0m     filename_prefix\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdigiface_pretrained\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     18\u001b[0m       )\n\u001b[1;32m     20\u001b[0m pretrained_model_digiface \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(model)\n\u001b[1;32m     21\u001b[0m \u001b[39m#load state dict from model-states/digiface_pretrained_final.pt\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 87\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(learning_rate, num_epochs, weight_decay, momentum, output_to_file, always_output, scheduling, lr_milestones, lr_gamma, eval, data_loader, loss_output_mod, filename_prefix, savestate)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m     86\u001b[0m     epoch_tic \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[0;32m---> 87\u001b[0m     \u001b[39mfor\u001b[39;00m imgs, labels \u001b[39min\u001b[39;00m \u001b[39miter\u001b[39m(data_loader):\n\u001b[1;32m     88\u001b[0m         tic \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mperf_counter()\n\u001b[1;32m     89\u001b[0m         imgs \u001b[39m=\u001b[39m imgs\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/envs/webface/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/webface/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/webface/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/webface/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/webface/lib/python3.10/site-packages/torchvision/datasets/folder.py:232\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m     sample \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(sample)\n\u001b[0;32m--> 232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n\u001b[1;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m sample, target\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "num_classes_pretrain = 2000\n",
    "model.fc = nn.Linear(512, num_classes_pretrain)\n",
    "model.to(device)\n",
    "\n",
    "train(\n",
    "    eval=False,\n",
    "    data_loader=pretrain_loader,\n",
    "    learning_rate=1e-3,\n",
    "    num_epochs=20,\n",
    "    output_to_file=False,\n",
    "    always_output=False,\n",
    "    scheduling=False,\n",
    "    loss_output_mod=100,\n",
    "    savestate=False,\n",
    "    filename_prefix='digiface_pretrained',\n",
    "      )\n",
    "\n",
    "pretrained_model_digiface = copy.deepcopy(model)\n",
    "#load state dict from model-states/digiface_pretrained_final.pt\n",
    "pretrained_model_digiface.load_state_dict(torch.load('model-states/digiface_pretrained_final.pt'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8b3cfb0",
   "metadata": {},
   "source": [
    "Train and eval on first 100 casia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0c9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pretrained_model_digiface\n",
    "model.fc = nn.Linear(512, 100)\n",
    "model.to(device)\n",
    "\n",
    "acc, predictions, labels = train(\n",
    "    num_epochs=20,\n",
    "    learning_rate=0.1,\n",
    "    eval=True,\n",
    "    data_loader=train_loader,\n",
    "    output_to_file=False,\n",
    "    always_output=True,\n",
    "    scheduling=True,\n",
    "    filename_prefix='digiface_casia',\n",
    "    savestate=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99b853c5",
   "metadata": {},
   "source": [
    "Pretrain on casia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e82685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1994\n"
     ]
    }
   ],
   "source": [
    "num_classes_pretrain = len(os.listdir('data/casia-144000/'))\n",
    "print(num_classes_pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "model = resnet18()\n",
    "model.fc = nn.Linear(512, num_classes_pretrain)\n",
    "model.to(device)\n",
    "\n",
    "train(\n",
    "    eval=False,\n",
    "    data_loader=pretrain_loader_casia,\n",
    "    learning_rate=1e-3,\n",
    "    num_epochs=20,\n",
    "    output_to_file=False,\n",
    "    always_output=False,\n",
    "    scheduling=False,\n",
    "    loss_output_mod=100,\n",
    "    savestate=False,\n",
    "    filename_prefix='casia_pretrained',\n",
    "      )\n",
    "\n",
    "pretrained_model_casia = copy.deepcopy(model)\n",
    "pretrained_model_casia.load_state_dict(torch.load('model-states/casia_pretrained_final.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b0de96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pretrained_model_casia\n",
    "model.fc = nn.Linear(512, 100)\n",
    "model.to(device)\n",
    "\n",
    "acc, predictions, labels = train(\n",
    "    num_epochs=20,\n",
    "    learning_rate=0.1,\n",
    "    eval=True,\n",
    "    data_loader=train_loader,\n",
    "    output_to_file=False,\n",
    "    always_output=True,\n",
    "    scheduling=True,\n",
    "    filename_prefix='casia_casia',\n",
    "    savestate=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77593b58",
   "metadata": {},
   "source": [
    "Load a resnet model with imagenet weights and train/eval again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807365c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(weights = ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(512, 100)\n",
    "model.to(device)\n",
    "\n",
    "acc, predictions, labels = train(\n",
    "    num_epochs=20,\n",
    "    learning_rate=0.1,\n",
    "    eval=True,\n",
    "    data_loader=train_loader,\n",
    "    output_to_file=False,\n",
    "    always_output=True,\n",
    "    scheduling=True,\n",
    "    filename_prefix='imagenet_casia',\n",
    "    savestate=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0346f00c",
   "metadata": {},
   "source": [
    "Load a clean resnet18 without any weights and train/eval again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4196357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18()\n",
    "model.fc = nn.Linear(512, 100)\n",
    "model.to(device)\n",
    "acc, predictions, labels = train(\n",
    "    num_epochs=20,\n",
    "    learning_rate=0.1,\n",
    "    eval=True,\n",
    "    data_loader=train_loader,\n",
    "    output_to_file=False,\n",
    "    always_output=True,\n",
    "    scheduling=True,\n",
    "    filename_prefix='imagenet_casia',\n",
    "    savestate=True,\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6aa12045",
   "metadata": {},
   "source": [
    "Reset experminent"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
