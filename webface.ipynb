{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_path = 'data/casia-webface'\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "train_data = datasets.ImageFolder(data_path, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    train_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure dataset is loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image tensor([[[0.4667, 0.4706, 0.4784,  ..., 0.5216, 0.5294, 0.5333],\n",
      "         [0.4667, 0.4706, 0.4784,  ..., 0.5176, 0.5255, 0.5294],\n",
      "         [0.4667, 0.4706, 0.4784,  ..., 0.5137, 0.5216, 0.5255],\n",
      "         ...,\n",
      "         [0.7137, 0.7176, 0.7255,  ..., 0.2392, 0.2392, 0.2353],\n",
      "         [0.7294, 0.7333, 0.7373,  ..., 0.2314, 0.2353, 0.2353],\n",
      "         [0.7373, 0.7412, 0.7451,  ..., 0.2275, 0.2314, 0.2353]],\n",
      "\n",
      "        [[0.4039, 0.4078, 0.4157,  ..., 0.2667, 0.2706, 0.2706],\n",
      "         [0.4039, 0.4078, 0.4157,  ..., 0.2627, 0.2667, 0.2667],\n",
      "         [0.4039, 0.4078, 0.4157,  ..., 0.2588, 0.2627, 0.2627],\n",
      "         ...,\n",
      "         [0.1961, 0.2000, 0.2078,  ..., 0.0667, 0.0667, 0.0627],\n",
      "         [0.1961, 0.2000, 0.2039,  ..., 0.0588, 0.0627, 0.0627],\n",
      "         [0.1961, 0.2000, 0.2039,  ..., 0.0549, 0.0588, 0.0627]],\n",
      "\n",
      "        [[0.4157, 0.4196, 0.4275,  ..., 0.3843, 0.3882, 0.3922],\n",
      "         [0.4157, 0.4196, 0.4275,  ..., 0.3804, 0.3843, 0.3882],\n",
      "         [0.4157, 0.4196, 0.4235,  ..., 0.3686, 0.3804, 0.3843],\n",
      "         ...,\n",
      "         [0.5529, 0.5569, 0.5647,  ..., 0.1255, 0.1255, 0.1216],\n",
      "         [0.5647, 0.5686, 0.5725,  ..., 0.1176, 0.1216, 0.1216],\n",
      "         [0.5686, 0.5725, 0.5765,  ..., 0.1137, 0.1176, 0.1216]]])\n",
      "label tensor(0)\n",
      "label tensor(0)\n",
      "label tensor(0)\n",
      "label tensor(0)\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(trainloader)\n",
    "image, label = next(iterator)\n",
    "\n",
    "assert label[0] == label[1]\n",
    "print(\"image\", image[0])\n",
    "print(\"label\", label[0])\n",
    "print(\"label\", label[1])\n",
    "print(\"label\", label[2])\n",
    "print(\"label\", label[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Init the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10572\n",
      "mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10572, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torch import nn, optim\n",
    "import os\n",
    "# model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model = resnet18()\n",
    "num_classes = len(os.listdir(data_path))\n",
    "print(num_classes)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "model.fc = nn.Linear(512, num_classes)\n",
    "model.to(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "learning_rate = 1e-3\n",
    "num_epochs = 10\n",
    "weight_decay = 0.0\n",
    "momentum = 0.9\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                    lr=learning_rate,\n",
    "                    momentum=momentum,\n",
    "                    weight_decay=weight_decay)\n",
    "\n",
    "def get_train_accuracy(model: nn.Module):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in iter(trainloader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device) # Move input data to the same device as the model\n",
    "            model.eval()\n",
    "            output = model(imgs) # We don't need to run torch.softmax\n",
    "            pred = output.max(1)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(labels).sum().item()\n",
    "            total += imgs.shape[0]\n",
    "            n += 1\n",
    "    return correct / total \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    n = 0\n",
    "    for imgs, labels in iter(trainloader):\n",
    "        tic = time.perf_counter()\n",
    "        # imshow(imgs[0])\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        model.train() # annotate model for training\n",
    "\n",
    "        out = model(imgs)\n",
    "        loss = loss_fn(out, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        toc = time.perf_counter()\n",
    "        n += 1\n",
    "        if n % 10 == 0:\n",
    "            print('epoch: {}, iter: {}, loss: {}, time: {}'.format(epoch, n, loss, toc - tic))\n",
    "    print(get_train_accuracy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
